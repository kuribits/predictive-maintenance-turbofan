{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turbofan POC: Populate nodes with data\n",
    "CAA 20/07/2020\n",
    "\n",
    "In this notebook, we will use use a coordinating server to distribute data to the nodes, either from a remote source or from a local directory.\n",
    "\n",
    "Dependencies for this notebook:\n",
    "- Python >= 3.7\n",
    "- PySyft 0.2.7\n",
    "\n",
    "NOTE: Before running this notebook, ensure that you have run `bash prep_turbofan.sh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "from syft.grid.clients.dynamic_fl_client import DynamicFLClient\n",
    "import torch\n",
    "import pandas as pd\n",
    "from numpy.random import laplace\n",
    "from math import floor\n",
    "\n",
    "from federated_trainer.helper.data_helper import _load_data, WINDOW_SIZE, _drop_unnecessary_columns, _transform_to_windowed_data, get_data_loader, _clip_rul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_rul_to_train_data(train_data):\n",
    "    \"\"\" Calculate and add the RUL to all rows in the given training data.\n",
    "\n",
    "    :param train_data: The training data\n",
    "    :return: The training data with added RULs\n",
    "    \"\"\"\n",
    "    # retrieve the max cycles per engine_node: RUL\n",
    "    train_rul = pd.DataFrame(train_data.groupby('engine_no')['time_in_cycles'].max()).reset_index()\n",
    "\n",
    "    # merge the RULs into the training data\n",
    "    train_rul.columns = ['engine_no', 'max']\n",
    "    train_data = train_data.merge(train_rul, on=['engine_no'], how='left')\n",
    "\n",
    "    # add the current RUL for every cycle\n",
    "    train_data['RUL'] = train_data['max'] - train_data['time_in_cycles']\n",
    "    train_data.drop('max', axis=1, inplace=True)\n",
    "\n",
    "    return train_data\n",
    "\n",
    "def round_to_multiple(x, base):\n",
    "    '''\n",
    "    Round x down to multiple of base\n",
    "    '''\n",
    "    return base * floor(x/base)\n",
    "\n",
    "def batch(tensor, batch_size):\n",
    "    features_size = tensor.shape[1:]\n",
    "    # shuffle and batch\n",
    "    randi = torch.randperm(tensor.shape[0])\n",
    "    # remove undersized tensor\n",
    "    out = tensor[randi].split(batch_size)[:-1]\n",
    "    out = torch.cat(out).view(-1, batch_size, *features_size)\n",
    "    return out\n",
    "\n",
    "def tuple_batch(tensors, batch_size):\n",
    "    '''\n",
    "    tensors: tuple of tensors\n",
    "    '''\n",
    "    return (batch(t, batch_size) for t in tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./data\"\n",
    "DATA_NAME = \"train_data_initial.txt\"\n",
    "MINIBATCH_SIZE = 4\n",
    "NOISE = 0.2\n",
    "DP_TYPE = 'local'\n",
    "LABEL_DISTR_SKEW = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "WARNING:root:Torch was already hooked... skipping hooking process\n"
    }
   ],
   "source": [
    "# Hook Torch\n",
    "hook = sy.TorchHook(torch)\n",
    "\n",
    "nodes = [\"ws://18.221.43.195:3000/\",\n",
    "         \"ws://18.221.43.195:3001/\"]\n",
    "\n",
    "compute_nodes = []\n",
    "for node in nodes:\n",
    "    compute_nodes.append(DynamicFLClient(hook, node))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset\n",
    "The code below will load prepared data from the Turbofan POC repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1209 features with shape (80, 11)\n1209 labels with shape (1209, 1)\n"
    }
   ],
   "source": [
    "data = _load_data(DATA_NAME, DATA_PATH)\n",
    "data_dropcol = _drop_unnecessary_columns(data)\n",
    "data_rul = add_rul_to_train_data(data_dropcol)\n",
    "x, y = _transform_to_windowed_data(data_rul, WINDOW_SIZE)\n",
    "y = _clip_rul(y)\n",
    " # transform to torch tensor\n",
    "tensor_x = torch.Tensor(x)\n",
    "tensor_y = torch.Tensor(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: Add differential privacy to data\n",
    "We can add noise to the data at this point if we want to simulate the addition of noise by distributed data owners."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def laplacian_mechanism(input_tensor, sensitivity=0.5, epsilon=0.05):\n",
    "    '''\n",
    "    sensitivity and epsilon are arbitrarily \n",
    "    chosen for now\n",
    "    '''\n",
    "    beta = sensitivity / epsilon\n",
    "    noise = torch.tensor(laplace(0, beta, 1))\n",
    "    return input_tensor + noise\n",
    "\n",
    "def add_noise(input_tensor, p_noise):\n",
    "    '''\n",
    "    tensor: input tensor\n",
    "    p_noise: probability with which noise is added\n",
    "    '''\n",
    "    be_honest = (torch.rand(input_tensor.shape) < p_noise).float()\n",
    "    tensor_artificial = laplacian_mechanism(input_tensor)\n",
    "    # add noise\n",
    "    mod_tensor = input_tensor.float() * be_honest + (1 - be_honest) * tensor_artificial\n",
    "    sk_tensor = mod_tensor.float().mean()\n",
    "    # de-skew result\n",
    "    noisy_tensor = ((mod_tensor / p_noise) - 0.5) * p_noise / (1 - p_noise)\n",
    "    return mod_tensor.type(torch.float32)\n",
    "\n",
    "if DP_TYPE=='local':\n",
    "    tensor_x = add_noise(tensor_x, NOISE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: Introduce skew (non-IIDness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_distribution_skew(x, y, partitions, skew=1):\n",
    "    def worker_split(N_labels, N_workers):\n",
    "        \"\"\"number of labels to assign to n workers\"\"\"\n",
    "        worker_labels = round(max(1, N_labels / N_workers))\n",
    "        worker_split = round(max(1, N_workers / N_labels))\n",
    "        return worker_labels, worker_split\n",
    "\n",
    "    worker_data = []\n",
    "    N_labels = torch.histc(y, bins=partitions, max=500)\n",
    "    n_labels, n_workers = worker_split(N_labels, partitions)\n",
    "    \n",
    "    worker_idx = 0\n",
    "    for label_idx in range(0, N_labels, n_labels):\n",
    "        mask = np.isin(y, range(label_idx, label_idx+n_labels))\n",
    "        subset_idx = np.argwhere(mask)[:, 0]\n",
    "        n_samples = subset_idx.shape[0]\n",
    "        sample_size = math.floor(skew*n_samples)\n",
    "        subset_idx = np.random.choice(subset_idx, sample_size, replace=False)\n",
    "        x_subset = x[subset_idx, ]\n",
    "        y_subset = y[subset_idx]   \n",
    "    \n",
    "        for partition in zip(np.array_split(x_subset, n_workers),\n",
    "                             np.array_split(y_subset, n_workers)):\n",
    "            worker_data.append(partition)\n",
    "    \n",
    "        x = np.delete(x, subset_idx, axis=0)\n",
    "        y = np.delete(y, subset_idx)    \n",
    "        worker_idx = worker_idx + n_workers\n",
    "\n",
    "    return worker_data, x, y\n",
    "\n",
    "if LABEL_DISTR_SKEW:\n",
    "    dataiter = label_distribution_skew(tensor_x, tensor_y, len(compute_nodes), skew=LABEL_DISTR_SKEW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not LABEL_DISTR_SKEW:\n",
    "    dataset_train = torch.utils.data.TensorDataset(tensor_x, tensor_y)\n",
    "    trainloader = torch.utils.data.DataLoader(dataset_train, \n",
    "        # split data equally among nodes with shuffle\n",
    "        batch_size=dataset_train.__len__()//len(compute_nodes),\n",
    "        shuffle=True,\n",
    "        drop_last=True,)\n",
    "        #pin_memory=True) for faster dataloading to CUDA\n",
    "    else: \n",
    "        trainloader = torch.utils.data.DataLoader(dataset_train, \n",
    "        # split data equally among nodes without shuffle\n",
    "        batch_size=dataset_train.__len__()//len(compute_nodes),\n",
    "        shuffle=False,\n",
    "        drop_last=True,)\n",
    "        #pin_memory=True) for faster dataloading to CUDA\n",
    "    dataiter = iter(trainloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag and send split datasets to each worker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Exception ignored in: <function ObjectPointer.__del__ at 0x7fc9f16960e0>\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/syft/generic/pointers/object_pointer.py\", line 346, in __del__\n    self.owner.send_msg(ForceObjectDeleteMessage(self.id_at_location), self.location)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/syft/workers/base.py\", line 309, in send_msg\n    bin_response = self._send_msg(bin_message, location)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/syft/workers/virtual.py\", line 16, in _send_msg\n    return location._recv_msg(message)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/syft/workers/websocket_client.py\", line 106, in _recv_msg\n    response = self._forward_to_websocket_server_worker(message)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/syft/grid/clients/dynamic_fl_client.py\", line 155, in _forward_to_websocket_server_worker\n    self.ws.send_binary(message)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/websocket/_core.py\", line 285, in send_binary\n    return self.send(payload, ABNF.OPCODE_BINARY)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/websocket/_core.py\", line 253, in send\n    return self.send_frame(frame)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/websocket/_core.py\", line 279, in send_frame\n    l = self._send(data)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/websocket/_core.py\", line 449, in _send\n    return send(self.sock, data)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/websocket/_socket.py\", line 135, in send\n    raise WebSocketConnectionClosedException(\"socket is already closed.\")\nwebsocket._exceptions.WebSocketConnectionClosedException: socket is already closed.\nException ignored in: <function ObjectPointer.__del__ at 0x7fc9f16960e0>\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/syft/generic/pointers/object_pointer.py\", line 346, in __del__\n    self.owner.send_msg(ForceObjectDeleteMessage(self.id_at_location), self.location)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/syft/workers/base.py\", line 309, in send_msg\n    bin_response = self._send_msg(bin_message, location)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/syft/workers/virtual.py\", line 16, in _send_msg\n    return location._recv_msg(message)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/syft/workers/websocket_client.py\", line 106, in _recv_msg\n    response = self._forward_to_websocket_server_worker(message)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/syft/grid/clients/dynamic_fl_client.py\", line 155, in _forward_to_websocket_server_worker\n    self.ws.send_binary(message)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/websocket/_core.py\", line 285, in send_binary\n    return self.send(payload, ABNF.OPCODE_BINARY)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/websocket/_core.py\", line 253, in send\n    return self.send_frame(frame)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/websocket/_core.py\", line 279, in send_frame\n    l = self._send(data)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/websocket/_core.py\", line 449, in _send\n    return send(self.sock, data)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/websocket/_socket.py\", line 135, in send\n    raise WebSocketConnectionClosedException(\"socket is already closed.\")\nwebsocket._exceptions.WebSocketConnectionClosedException: socket is already closed.\nException ignored in: <function ObjectPointer.__del__ at 0x7fc9f16960e0>\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/syft/generic/pointers/object_pointer.py\", line 346, in __del__\n    self.owner.send_msg(ForceObjectDeleteMessage(self.id_at_location), self.location)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/syft/workers/base.py\", line 309, in send_msg\n    bin_response = self._send_msg(bin_message, location)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/syft/workers/virtual.py\", line 16, in _send_msg\n    return location._recv_msg(message)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/syft/workers/websocket_client.py\", line 106, in _recv_msg\n    response = self._forward_to_websocket_server_worker(message)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/syft/grid/clients/dynamic_fl_client.py\", line 155, in _forward_to_websocket_server_worker\n    self.ws.send_binary(message)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/websocket/_core.py\", line 285, in send_binary\n    return self.send(payload, ABNF.OPCODE_BINARY)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/websocket/_core.py\", line 253, in send\n    return self.send_frame(frame)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/websocket/_core.py\", line 279, in send_frame\n    l = self._send(data)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/websocket/_core.py\", line 449, in _send\n    return send(self.sock, data)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/websocket/_socket.py\", line 135, in send\n    raise WebSocketConnectionClosedException(\"socket is already closed.\")\nwebsocket._exceptions.WebSocketConnectionClosedException: socket is already closed.\nException ignored in: <function ObjectPointer.__del__ at 0x7fc9f16960e0>\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/syft/generic/pointers/object_pointer.py\", line 346, in __del__\n    self.owner.send_msg(ForceObjectDeleteMessage(self.id_at_location), self.location)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/syft/workers/base.py\", line 309, in send_msg\n    bin_response = self._send_msg(bin_message, location)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/syft/workers/virtual.py\", line 16, in _send_msg\n    return location._recv_msg(message)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/syft/workers/websocket_client.py\", line 106, in _recv_msg\n    response = self._forward_to_websocket_server_worker(message)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/syft/grid/clients/dynamic_fl_client.py\", line 155, in _forward_to_websocket_server_worker\n    self.ws.send_binary(message)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/websocket/_core.py\", line 285, in send_binary\n    return self.send(payload, ABNF.OPCODE_BINARY)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/websocket/_core.py\", line 253, in send\n    return self.send_frame(frame)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/websocket/_core.py\", line 279, in send_frame\n    l = self._send(data)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/websocket/_core.py\", line 449, in _send\n    return send(self.sock, data)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/websocket/_socket.py\", line 135, in send\n    raise WebSocketConnectionClosedException(\"socket is already closed.\")\nwebsocket._exceptions.WebSocketConnectionClosedException: socket is already closed.\nException ignored in: <function ObjectPointer.__del__ at 0x7fc9f16960e0>\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/syft/generic/pointers/object_pointer.py\", line 346, in __del__\n    self.owner.send_msg(ForceObjectDeleteMessage(self.id_at_location), self.location)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/syft/workers/base.py\", line 309, in send_msg\n    bin_response = self._send_msg(bin_message, location)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/syft/workers/virtual.py\", line 16, in _send_msg\n    return location._recv_msg(message)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/syft/workers/websocket_client.py\", line 106, in _recv_msg\n    response = self._forward_to_websocket_server_worker(message)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/syft/grid/clients/dynamic_fl_client.py\", line 155, in _forward_to_websocket_server_worker\n    self.ws.send_binary(message)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/websocket/_core.py\", line 285, in send_binary\n    return self.send(payload, ABNF.OPCODE_BINARY)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/websocket/_core.py\", line 253, in send\n    return self.send_frame(frame)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/websocket/_core.py\", line 279, in send_frame\n    l = self._send(data)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/websocket/_core.py\", line 449, in _send\n    return send(self.sock, data)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/websocket/_socket.py\", line 135, in send\n    raise WebSocketConnectionClosedException(\"socket is already closed.\")\nwebsocket._exceptions.WebSocketConnectionClosedException: socket is already closed.\nException ignored in: <function ObjectPointer.__del__ at 0x7fc9f16960e0>\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/syft/generic/pointers/object_pointer.py\", line 346, in __del__\n    self.owner.send_msg(ForceObjectDeleteMessage(self.id_at_location), self.location)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/syft/workers/base.py\", line 309, in send_msg\n    bin_response = self._send_msg(bin_message, location)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/syft/workers/virtual.py\", line 16, in _send_msg\n    return location._recv_msg(message)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/syft/workers/websocket_client.py\", line 106, in _recv_msg\n    response = self._forward_to_websocket_server_worker(message)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/syft/grid/clients/dynamic_fl_client.py\", line 155, in _forward_to_websocket_server_worker\n    self.ws.send_binary(message)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/websocket/_core.py\", line 285, in send_binary\n    return self.send(payload, ABNF.OPCODE_BINARY)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/websocket/_core.py\", line 253, in send\n    return self.send_frame(frame)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/websocket/_core.py\", line 279, in send_frame\n    l = self._send(data)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/websocket/_core.py\", line 449, in _send\n    return send(self.sock, data)\n  File \"/home/ubuntu/anaconda3/envs/syft/lib/python3.7/site-packages/websocket/_socket.py\", line 135, in send\n    raise WebSocketConnectionClosedException(\"socket is already closed.\")\nwebsocket._exceptions.WebSocketConnectionClosedException: socket is already closed.\ntorch.Size([150, 4, 80, 11]) torch.Size([150, 4, 1])\ntorch.Size([150, 4, 80, 11]) torch.Size([150, 4, 1])\n"
    }
   ],
   "source": [
    "\n",
    "shared_x = []\n",
    "shared_y = []\n",
    "for node in compute_nodes:\n",
    "    # create minibatches\n",
    "    worker_batch = dataiter.next()\n",
    "    sensors_train_tfan, labels_train_tfan = tuple_batch(worker_batch, MINIBATCH_SIZE)\n",
    "    print(sensors_train_tfan.shape, labels_train_tfan.shape)\n",
    "    # Tag tensors (allows them to be retrieved later)\n",
    "    if not DP_TYPE:\n",
    "        tagged_sensors = sensors_train_tfan.tag(\"#X\", \"#turbofan\", \"#dataset\").describe(\"The input datapoints to the Turbofan dataset.\")\n",
    "    elif DP_TYPE=='local':\n",
    "        tagged_sensors = sensors_train_tfan.tag(\"#X\", \"#localdp\", \"#turbofan\", \"#dataset\").describe(\"The input datapoints to the Turbofan dataset.\")\n",
    "    tagged_label = labels_train_tfan.tag(\"#Y\", \"#turbofan\", \"#dataset\").describe(\"The input labels to the Turbofan dataset.\")\n",
    "    \n",
    "    shared_x.append(tagged_sensors.send(node))\n",
    "    shared_y.append(tagged_label.send(node))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "X tensor pointers:  [(Wrapper)>[PointerTensor | me:56856317696 -> alice:75639148278]\n\tTags: #localdp #X #turbofan #dataset \n\tShape: torch.Size([150, 4, 80, 11])\n\tDescription: The input datapoints to the Turbofan dataset...., (Wrapper)>[PointerTensor | me:9037347334 -> bob:28395798793]\n\tTags: #localdp #X #turbofan #dataset \n\tShape: torch.Size([150, 4, 80, 11])\n\tDescription: The input datapoints to the Turbofan dataset....]\nY tensor pointers:  [(Wrapper)>[PointerTensor | me:658473828 -> alice:93578425169]\n\tTags: #Y #turbofan #dataset \n\tShape: torch.Size([150, 4, 1])\n\tDescription: The input labels to the Turbofan dataset...., (Wrapper)>[PointerTensor | me:82313452988 -> bob:21619885372]\n\tTags: #Y #turbofan #dataset \n\tShape: torch.Size([150, 4, 1])\n\tDescription: The input labels to the Turbofan dataset....]\n"
    }
   ],
   "source": [
    "# print(\"X tensor pointers: \", shared_x1, shared_x2)\n",
    "# print(\"Y tensor pointers: \", shared_y1, shared_y2)\n",
    "\n",
    "print(\"X tensor pointers: \", shared_x)\n",
    "print(\"Y tensor pointers: \", shared_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disconnect nodes\n",
    "\n",
    "To ensure that our training process (in the Part 2 notebook), if located on the same server, is not using cached or local data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in compute_nodes:\n",
    "    node.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('syft': conda)",
   "language": "python",
   "name": "python_defaultSpec_1596064016799"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}